# This file is automatically generated by the rmf-codegen project.
#
# The Python code generator is maintained by Lab Digital. If you want to
# contribute to this project then please do not edit this file directly
# but send a pull request to the Lab Digital fork of rmf-codegen at
# https://github.com/labd/rmf-codegen

import datetime
import enum
import typing

from ._abstract import _BaseType
from .common import ImportResource, ProductPriceModeEnum

if typing.TYPE_CHECKING:
    from .common import (
        CategoryKeyReference,
        LocalizedString,
        ProductPriceModeEnum,
        ProductTypeKeyReference,
        StateKeyReference,
        TaxCategoryKeyReference,
    )

__all__ = [
    "CustomTokenizer",
    "ProductImport",
    "SearchKeyword",
    "SearchKeywords",
    "SuggestTokenizer",
    "WhitespaceTokenizer",
]


class SearchKeywords(typing.Dict[str, typing.List["SearchKeyword"]]):
    pass


class SearchKeyword(_BaseType):
    text: str
    #: The tokenizer defines the tokens that are used to match against the [Suggest Query](/../products-suggestions#suggest-query) input.
    suggest_tokenizer: typing.Optional["SuggestTokenizer"]

    def __init__(
        self,
        *,
        text: str,
        suggest_tokenizer: typing.Optional["SuggestTokenizer"] = None
    ):
        self.text = text
        self.suggest_tokenizer = suggest_tokenizer

        super().__init__()

    @classmethod
    def deserialize(cls, data: typing.Dict[str, typing.Any]) -> "SearchKeyword":
        from ._schemas.products import SearchKeywordSchema

        return SearchKeywordSchema().load(data)

    def serialize(self) -> typing.Dict[str, typing.Any]:
        from ._schemas.products import SearchKeywordSchema

        return SearchKeywordSchema().dump(self)


class SuggestTokenizer(_BaseType):
    """The tokenizer defines the tokens that are used to match against the [Suggest Query](/../products-suggestions#suggest-query) input."""

    type: str

    def __init__(self, *, type: str):
        self.type = type

        super().__init__()

    @classmethod
    def deserialize(cls, data: typing.Dict[str, typing.Any]) -> "SuggestTokenizer":
        if data["type"] == "custom":
            from ._schemas.products import CustomTokenizerSchema

            return CustomTokenizerSchema().load(data)
        if data["type"] == "whitespace":
            from ._schemas.products import WhitespaceTokenizerSchema

            return WhitespaceTokenizerSchema().load(data)

    def serialize(self) -> typing.Dict[str, typing.Any]:
        from ._schemas.products import SuggestTokenizerSchema

        return SuggestTokenizerSchema().dump(self)


class CustomTokenizer(SuggestTokenizer):
    inputs: typing.List["str"]

    def __init__(self, *, inputs: typing.List["str"]):
        self.inputs = inputs

        super().__init__(type="custom")

    @classmethod
    def deserialize(cls, data: typing.Dict[str, typing.Any]) -> "CustomTokenizer":
        from ._schemas.products import CustomTokenizerSchema

        return CustomTokenizerSchema().load(data)

    def serialize(self) -> typing.Dict[str, typing.Any]:
        from ._schemas.products import CustomTokenizerSchema

        return CustomTokenizerSchema().dump(self)


class WhitespaceTokenizer(SuggestTokenizer):
    def __init__(self):
        super().__init__(type="whitespace")

    @classmethod
    def deserialize(cls, data: typing.Dict[str, typing.Any]) -> "WhitespaceTokenizer":
        from ._schemas.products import WhitespaceTokenizerSchema

        return WhitespaceTokenizerSchema().load(data)

    def serialize(self) -> typing.Dict[str, typing.Any]:
        from ._schemas.products import WhitespaceTokenizerSchema

        return WhitespaceTokenizerSchema().dump(self)


class ProductImport(ImportResource):
    """The data representation for a Product to be imported that is persisted as a [Product](/../api/projects/products#product) in the Project.

    This is the minimal representation required for creating a [Product](/../api/projects/products#product) in commercetools.

    """

    #: Maps to `Product.name`.
    name: "LocalizedString"
    #: The `productType` of a [Product](/../api/projects/products#product).
    #: Maps to `Product.productType`.
    #: The Reference to the [ProductType](/../api/projects/productTypes#producttype) with which the Product is associated.
    #: If referenced ProductType does not exist, the `state` of the [ImportOperation](/import-operation#importoperation) will be set to `unresolved` until the necessary ProductType is created.
    product_type: "ProductTypeKeyReference"
    #: Human-readable identifiers usually used as deep-link URL to the related product. Each slug must be unique across a Project,
    #: but a product can have the same slug for different languages. Allowed are alphabetic, numeric, underscore (_) and hyphen (-) characters.
    slug: "LocalizedString"
    #: Maps to `Product.description`.
    description: typing.Optional["LocalizedString"]
    #: Maps to `Product.categories`.
    #: The References to the [Categories](/../api/projects/categories#category) with which the Product is associated.
    #: If referenced Categories do not exist, the `state` of the [ImportOperation](/import-operation#importoperation) will be set to `unresolved` until the necessary Categories are created.
    categories: typing.Optional[typing.List["CategoryKeyReference"]]
    #: A localized string is a JSON object where the keys are of [IETF language tag](https://en.wikipedia.org/wiki/IETF_language_tag), and the values the corresponding strings used for that language.
    #: ```json
    #: {
    #:   "de": "Hundefutter",
    #:   "en": "dog food"
    #: }
    #: ```
    meta_title: typing.Optional["LocalizedString"]
    #: A localized string is a JSON object where the keys are of [IETF language tag](https://en.wikipedia.org/wiki/IETF_language_tag), and the values the corresponding strings used for that language.
    #: ```json
    #: {
    #:   "de": "Hundefutter",
    #:   "en": "dog food"
    #: }
    #: ```
    meta_description: typing.Optional["LocalizedString"]
    #: A localized string is a JSON object where the keys are of [IETF language tag](https://en.wikipedia.org/wiki/IETF_language_tag), and the values the corresponding strings used for that language.
    #: ```json
    #: {
    #:   "de": "Hundefutter",
    #:   "en": "dog food"
    #: }
    #: ```
    meta_keywords: typing.Optional["LocalizedString"]
    #: The Reference to the [TaxCategory](/../api/projects/taxCategories#taxcategory) with which the Product is associated.
    #: If referenced TaxCategory does not exist, the `state` of the [ImportOperation](/import-operation#importoperation) will be set to `unresolved` until the necessary TaxCategory is created.
    tax_category: typing.Optional["TaxCategoryKeyReference"]
    #: Search keywords are primarily used by the suggester but are also considered for the full-text search. SearchKeywords is a JSON object where the keys are of [IETF language tag](https://en.wikipedia.org/wiki/IETF_language_tag). The value to a language tag key is an array of SearchKeyword for the specific language.
    #: ```json
    #: {
    #:   "en": [
    #:     { "text": "Multi tool" },
    #:     { "text": "Swiss Army Knife", "suggestTokenizer": { "type": "whitespace" } }
    #:   ],
    #:   "de": [
    #:     {
    #:       "text": "Schweizer Messer",
    #:       "suggestTokenizer": {
    #:         "type": "custom",
    #:         "inputs": ["schweizer messer", "offiziersmesser", "sackmesser"]
    #:       }
    #:     }
    #:   ]
    #: }
    #: ```
    search_keywords: typing.Optional["SearchKeywords"]
    #: The Reference to the [State](/../api/projects/states#state) with which the Product is associated.
    #: If referenced State does not exist, the `state` of the [ImportOperation](/import-operation#importoperation) will be set to `unresolved` until the necessary State is created.
    state: typing.Optional["StateKeyReference"]
    #: If `publish` is set to either `true` or `false`, both staged and current projections are set to the same value provided by the import data.
    #: If `publish` is not set, the staged projection is set to the provided import data, but the current projection stays unchanged.
    #: However, if the import data contains no update, that is, if it matches the staged projection of the existing Product, the import induces no change in the existing Product whether `publish` is set or not.
    publish: typing.Optional[bool]
    #: Determines the type of Prices the API uses. See [ProductPriceMode](/../api/projects/products#productpricemode) for more details. If not provided, the existing `Product.priceMode` is not changed.
    price_mode: typing.Optional["ProductPriceModeEnum"]

    def __init__(
        self,
        *,
        key: str,
        name: "LocalizedString",
        product_type: "ProductTypeKeyReference",
        slug: "LocalizedString",
        description: typing.Optional["LocalizedString"] = None,
        categories: typing.Optional[typing.List["CategoryKeyReference"]] = None,
        meta_title: typing.Optional["LocalizedString"] = None,
        meta_description: typing.Optional["LocalizedString"] = None,
        meta_keywords: typing.Optional["LocalizedString"] = None,
        tax_category: typing.Optional["TaxCategoryKeyReference"] = None,
        search_keywords: typing.Optional["SearchKeywords"] = None,
        state: typing.Optional["StateKeyReference"] = None,
        publish: typing.Optional[bool] = None,
        price_mode: typing.Optional["ProductPriceModeEnum"] = None
    ):
        self.name = name
        self.product_type = product_type
        self.slug = slug
        self.description = description
        self.categories = categories
        self.meta_title = meta_title
        self.meta_description = meta_description
        self.meta_keywords = meta_keywords
        self.tax_category = tax_category
        self.search_keywords = search_keywords
        self.state = state
        self.publish = publish
        self.price_mode = price_mode

        super().__init__(key=key)

    @classmethod
    def deserialize(cls, data: typing.Dict[str, typing.Any]) -> "ProductImport":
        from ._schemas.products import ProductImportSchema

        return ProductImportSchema().load(data)

    def serialize(self) -> typing.Dict[str, typing.Any]:
        from ._schemas.products import ProductImportSchema

        return ProductImportSchema().dump(self)
